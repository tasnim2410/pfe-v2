{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7959a7e2",
   "metadata": {},
   "source": [
    "Automatic data export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3e6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf079db",
   "metadata": {},
   "source": [
    "the script below is a scraper class that automates the flow of finding and downloading patent listings from Espacenet in a few steps : \n",
    "- it launches an undetected chrome browser with special setting to look less like a robot . \n",
    "- based on the keywords and search fields the user provides it builds the correct search link .\n",
    "- it navigates to the link , waits until the page is fully loaded and then pauses briefly to mimic human behaviour . \n",
    "- it clicks the 'more options' button , then the 'download' section and finall the 'list csv' option to start the search results download. \n",
    "- when the download pop-up appears , it sets the number of patents to the maximum amount allowed (500) and clicks the download button \n",
    "- if anything goes wrong and the attempt is timed out , it will refresh the page and try again up to 3 times \n",
    "- once the CSV download has been triggered successfully ,it shuts down the browser cleanly .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15b745d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EspacenetScraper:\n",
    "    def __init__(self, search_keywords, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options and search keywords.\"\"\"\n",
    "        self.search_keywords = search_keywords\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  \n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.set_window_size(1600, 1300)\n",
    "\n",
    "    def construct_search_url(self):\n",
    "        \"\"\"Construct the search URL based on the provided keywords and their search fields.\"\"\"\n",
    "        base_url = 'https://worldwide.espacenet.com/patent/search?q='\n",
    "        \n",
    "        # Mapping of search fields to Espacenet query parameters\n",
    "        field_mapping = {\n",
    "            'title': 'ti',\n",
    "            'abstract': 'ab',\n",
    "            'claims': 'cl',\n",
    "            'title,abstract or claims': 'ctxt' ,\n",
    "            'all text fields' : 'ftxt',\n",
    "            'title or abstract' : 'ta',\n",
    "            'description' : 'desc',\n",
    "            'all text fields or names' : 'nftxt',\n",
    "            'title , abstract or names' : 'ntxt'\n",
    "             \n",
    "        }\n",
    "        \n",
    "        query_parts = []\n",
    "        for keyword, field in self.search_keywords.items():\n",
    "            field_param = field_mapping.get(field, 'ctxt')  # Default to 'ctxt' if field is unknown\n",
    "            query_parts.append(f'{field_param} = \"{keyword}\"')\n",
    "        \n",
    "        query = ' AND '.join(query_parts)\n",
    "        query += '&queryLang=en%3Ade%3Afr'\n",
    "        \n",
    "        return base_url + query\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, retries=3):\n",
    "        \"\"\"\n",
    "        Navigate to the constructed URL and return the page HTML.\n",
    "        Retry the operation if a timeout occurs.\n",
    "\n",
    "        Args:\n",
    "            retries (int): Number of retry attempts.\n",
    "\n",
    "        Returns:\n",
    "            str: The page HTML, or None if all retries fail.\n",
    "        \"\"\"\n",
    "        url = self.construct_search_url()\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                print(f\"Navigating to: {url} (Attempt {attempt + 1})\")\n",
    "                self.driver.get(url)\n",
    "                WebDriverWait(self.driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "\n",
    "                # Add a random delay to mimic human behavior\n",
    "                self.add_random_delay(3, 5)\n",
    "\n",
    "                # Return the page HTML\n",
    "                return self.driver.page_source\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(f\"Timed out waiting for the page to load. Retrying ({attempt + 1}/{retries})...\")\n",
    "                if attempt == retries - 1:\n",
    "                    print(\"Max retries reached. Unable to load the page.\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "\n",
    "    def download_csv(self, retries=3, max_results=500):\n",
    "        \"\"\"\n",
    "        Complete the sequence of clicking:\n",
    "        1. More Options button\n",
    "        2. Download dropdown\n",
    "        3. List (CSV) option\n",
    "        4. Handle download dialog by:\n",
    "           - Setting the \"To\" value to max_results (e.g., 500)\n",
    "           - Clicking the Download button\n",
    "        \n",
    "        Args:\n",
    "            retries (int): Number of retry attempts for the entire sequence.\n",
    "            max_results (int): Maximum number of results to download (1-500).\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the download sequence was successful, False otherwise.\n",
    "        \"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                print(f\"Attempting download sequence (Attempt {attempt + 1})...\")\n",
    "                \n",
    "                # Step 1: Click \"More Options\" button\n",
    "                print(\"Looking for More Options button...\")\n",
    "                more_options_selector = \"#more-options-selector--publication-list-header\"\n",
    "                more_options_button = WebDriverWait(self.driver, 30).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, more_options_selector))\n",
    "                )\n",
    "                \n",
    "                # Try to click, but handle intercepted clicks\n",
    "                try:\n",
    "                    print(\"More Options button found. Clicking...\")\n",
    "                    more_options_button.click()\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(\"Click intercepted, trying JavaScript click...\")\n",
    "                    self.driver.execute_script('document.querySelector(\"#more-options-selector--publication-list-header\").click()', more_options_button)\n",
    "                    \n",
    "                self.add_random_delay(2, 3)\n",
    "                print('More Options clicked successfully')\n",
    "                \n",
    "                # Step 2: Click \"Download\" section in the dropdown\n",
    "                print(\"Looking for Download section...\")\n",
    "                # Use a more general selector to find the Download section\n",
    "                # This uses contains() to match the text rather than a fixed CSS path\n",
    "                download_section_xpath = \"/html/body/div[2]/div[3]/ul/section[1]\"\n",
    "                download_section = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, download_section_xpath))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    print(\"Download section found. Clicking...\")\n",
    "                    download_section.click()\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(\"Click intercepted, trying JavaScript click...\")\n",
    "                    self.driver.execute_script('document.querySelector(\"#simple-dropdown > div.prod-jss1034.prod-jss966.prod-jss969.prod-jss1045 > ul > section:nth-child(1)\").click()', download_section)\n",
    "                    \n",
    "                self.add_random_delay(1, 2)\n",
    "                print('Download section clicked successfully')\n",
    "                \n",
    "                # Step 3: Click \"List (CSV)\" option\n",
    "                print(\"Looking for List (CSV) option...\")\n",
    "                # Use contains() with the XPATH to find the CSV option based on text\n",
    "                csv_option_xpath = \"/html/body/div[2]/div[3]/ul/li[2]\"\n",
    "                csv_option = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, csv_option_xpath))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    print(\"List (CSV) option found. Clicking...\")\n",
    "                    csv_option.click()\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(\"Click intercepted, trying JavaScript click...\")\n",
    "                    self.driver.execute_script('document.querySelector(\"#simple-dropdown > div.prod-jss1034.prod-jss966.prod-jss969.prod-jss1045 > ul > li:nth-child(3)\").click()', csv_option)\n",
    "                    \n",
    "                self.add_random_delay(2, 3)\n",
    "                print('List (CSV) option clicked successfully')\n",
    "                \n",
    "                # Step 4: Handle the download dialog\n",
    "                print(\"Waiting for download dialog to appear...\")\n",
    "                \n",
    "                # Wait for the dialog to appear\n",
    "                download_dialog_xpath = \"/html/body/div[2]/div[3]/div/div\"\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, download_dialog_xpath))\n",
    "                )\n",
    "                print(\"Download dialog appeared\")\n",
    "                \n",
    "                # Find the \"To\" input field\n",
    "                to_input_xpath = \"/html/body/div[2]/div[3]/div/div/div/div[1]/input[2]\"\n",
    "                to_input = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, to_input_xpath))\n",
    "                )\n",
    "                \n",
    "                # Clear the input and set it to max_results\n",
    "                print(f\"Setting maximum results to {max_results}...\")\n",
    "                to_input.clear()\n",
    "                to_input.send_keys(str(max_results))\n",
    "                self.add_random_delay(1, 2)\n",
    "                \n",
    "                # Click the Download button in the dialog\n",
    "                download_button_xpath = \"/html/body/div[2]/div[3]/div/div/div/button\"\n",
    "                download_button = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, download_button_xpath))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    print(\"Download button found. Clicking...\")\n",
    "                    download_button.click()\n",
    "                except ElementClickInterceptedException:\n",
    "                    print(\"Click intercepted, trying JavaScript click...\")\n",
    "                    self.driver.execute_script('document.querySelector(\"body > div.prod-jss12 > div.prod-jss15.prod-jss13 > div > div > div > button\").click()', download_button)\n",
    "                \n",
    "                print(\"Download button clicked\")\n",
    "                \n",
    "                # Wait for a moment to ensure the download starts\n",
    "                self.add_random_delay(3, 5)\n",
    "                \n",
    "                # Check if there are any error messages\n",
    "                try:\n",
    "                    error_message = self.driver.find_element(By.XPATH, \"//div[contains(@class, 'download-modal__validation')]//span\")\n",
    "                    if error_message.is_displayed() and error_message.text.strip():\n",
    "                        print(f\"Error in download dialog: {error_message.text}\")\n",
    "                        return False\n",
    "                except:\n",
    "                    # No error message found, continue\n",
    "                    pass\n",
    "                \n",
    "                print(\"Download sequence completed successfully\")\n",
    "                return True\n",
    "                \n",
    "            except TimeoutException as e:\n",
    "                print(f\"Timeout during download sequence: {e}\")\n",
    "                if attempt == retries - 1:\n",
    "                    print(\"Max retries reached. Download sequence failed.\")\n",
    "                    return False\n",
    "            except Exception as e:\n",
    "                print(f\"Error during download sequence: {e}\")\n",
    "                if attempt == retries - 1:\n",
    "                    print(\"Max retries reached. Download sequence failed.\")\n",
    "                    return False\n",
    "                \n",
    "            # If we reach here, there was an error and we need to try again\n",
    "            # Refresh the page before the next attempt\n",
    "            try:\n",
    "                self.driver.refresh()\n",
    "                WebDriverWait(self.driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "                self.add_random_delay(3, 5)\n",
    "            except Exception as e:\n",
    "                print(f\"Error refreshing page: {e}\")\n",
    "\n",
    "        return False\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7846f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Search URL: https://worldwide.espacenet.com/patent/search?q=ctxt = \"Silicon\" AND ctxt = \"crystal\" AND ctxt = \"lattice\"&queryLang=en%3Ade%3Afr\n",
      "Navigating to: https://worldwide.espacenet.com/patent/search?q=ctxt = \"Silicon\" AND ctxt = \"crystal\" AND ctxt = \"lattice\"&queryLang=en%3Ade%3Afr (Attempt 1)\n",
      "Page HTML retrieved successfully.\n",
      "Attempting download sequence (Attempt 1)...\n",
      "Looking for More Options button...\n",
      "More Options button found. Clicking...\n",
      "More Options clicked successfully\n",
      "Looking for Download section...\n",
      "Download section found. Clicking...\n",
      "Download section clicked successfully\n",
      "Looking for List (CSV) option...\n",
      "List (CSV) option found. Clicking...\n",
      "List (CSV) option clicked successfully\n",
      "Waiting for download dialog to appear...\n",
      "Download dialog appeared\n",
      "Setting maximum results to 500...\n",
      "Download button found. Clicking...\n",
      "Download button clicked\n",
      "Download sequence completed successfully\n",
      "CSV download initiated successfully.\n",
      "Download should be complete or in progress.\n",
      "Scraper closed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the search keywords with their search fields\n",
    "    search_keywords = {\n",
    "        \"Silicon\": \"title,abstract or claims\",\n",
    "        \"crystal\": \"title,abstract or claims\",\n",
    "        \"lattice\": \"title,abstract or claims\"\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "    # Initialize the scraper with the search keywords\n",
    "    scraper = EspacenetScraper(search_keywords, headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    try:\n",
    "        # Construct and print the search URL\n",
    "        search_url = scraper.construct_search_url()\n",
    "        print(\"Constructed Search URL:\", search_url)\n",
    "        \n",
    "        # Get the page HTML\n",
    "        html = scraper.get_page_html(retries=3)\n",
    "        if html:\n",
    "            print(\"Page HTML retrieved successfully.\")\n",
    "\n",
    "            # Perform the download sequence with max 500 results\n",
    "            if scraper.download_csv(retries=3, max_results=500):\n",
    "                print(\"CSV download initiated successfully.\")\n",
    "                # Wait a bit to ensure the download starts\n",
    "                time.sleep(10)\n",
    "                print(\"Download should be complete or in progress.\")\n",
    "            else:\n",
    "                print(\"Failed to download CSV.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd1141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest downloaded file: C:\\Users\\tasni/Downloads\\Résultat_de_la_recherche_dans_Espacenet_20250515_2004.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "downloads_folder = os.path.expanduser(\"~/Downloads\")\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(downloads_folder, \"*.csv\"))\n",
    "\n",
    "if list_of_files:  \n",
    "    latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "    print(\"Latest downloaded file:\", latest_file)\n",
    "\n",
    "   \n",
    "    \n",
    "    df = pd.read_csv(latest_file,delimiter=';', skiprows=7)\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"No CSV files found in Downloads.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baaab67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df.rename(columns={\n",
    "    'Titre': 'Title',\n",
    "    'Inventeurs': 'Inventors',\n",
    "    'Demandeurs': 'Applicants',\n",
    "    'Numéro de publication': 'Publication number',\n",
    "    'Priorité la plus ancienne': 'Earliest priority',\n",
    "    'CIB': 'IPC',\n",
    "    'CPC': 'CPC',\n",
    "    'Date de publication': 'Publication date',\n",
    "    'Publication la plus ancienne': 'Earliest publication',\n",
    "    'Numéro de famille': 'Family number'\n",
    "}, inplace=True)\n",
    "\n",
    "df[['first publication date','second publication date']] = df['Publication date'].str.split(' ' , n=1 , expand= True)\n",
    "df['second publication date'] = df['second publication date'].str.strip('\\n')\n",
    "df['second publication date'] = df['second publication date'].str.strip('\\r')\n",
    "df['second publication date'] = df['second publication date'].str.strip('\\n')\n",
    "\n",
    "\n",
    "df['first publication date'] = pd.to_datetime(\n",
    "    df['first publication date'].str.strip(), \n",
    "    format='mixed'\n",
    ")\n",
    "#first filing country \n",
    "df[['first publication number', 'second publication number']] = df['Publication number'].str.split(' ' , n=1 , expand=True)\n",
    "\n",
    "df['second publication number']=df['second publication number'].str.strip('\\n')\n",
    "df['first publication country'] = df['first publication number'].str[:2]\n",
    "df['second publication country'] = df['second publication number'].str[:2]\n",
    "if 'Unnamed: 11' in df.columns:\n",
    "    df = df.drop('Unnamed: 11', axis=1)\n",
    "    \n",
    "df['first filing year'] = df['first publication date'].dt.year\n",
    "\n",
    "\n",
    "df['Earliest priority'] = pd.to_datetime(df['Earliest priority'])\n",
    "df['earliest priority year'] = df['Earliest priority'].dt.year\n",
    "\n",
    "df['applicant country'] = df['Applicants'].str.extract(r'\\[([A-Z]{2})\\]')\n",
    "\n",
    "df = df.dropna(subset=['Inventors'])\n",
    "df['Applicants'] = df['Applicants'].fillna(df['Inventors'])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.dropna(subset=['Inventors','Applicants','IPC'])\n",
    "\n",
    "#filling missing CPC values \n",
    "df['CPC'] = df['CPC'].fillna('unkown')\n",
    "df['IPC'] = df['IPC'].str.split(r'\\s+')\n",
    "import re\n",
    "\n",
    "def split_cpc(classification):\n",
    "    # Split only at \") \" but keep the \")\"\n",
    "    parts = re.split(r'\\)\\s+', classification)  \n",
    "    return [p + ')' if not p.endswith(')') else p for p in parts]  # Ensure each part ends with ')'\n",
    "\n",
    "\n",
    "df['CPC'] = df['CPC'].apply(split_cpc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918cced",
   "metadata": {},
   "source": [
    "this script automates pulling patent-family data from espacenet using API . \n",
    "first it loads the consumer key and consumer_secret from .enf and caches an authentification token , then for each patent number in the dataframe it : \n",
    "- validates the format with a quick length check . \n",
    "- builds the request URL for the family endpoint (URL encoding the publication number)\n",
    "- sends the request to fetch patent family info in JSON \n",
    "- parses the JSON to collect all family member publication numbers and unique country codes .\n",
    "- batches these calls in groups of 100 with small delays between requests to respect rate limit .\n",
    "- maps the results back into two new dataframe columns family_jurisdictions and family_members and returns the enriched dataframe for export or further analysis .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d7395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 1/5\n",
      "Pausing between batches...\n",
      "\n",
      "Processing batch 2/5\n",
      "Pausing between batches...\n",
      "\n",
      "Processing batch 3/5\n",
      "Error processing patent CN110488413A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN110488413A (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001FF8434C290>, 'Connection to ops.epo.org timed out. (connect timeout=15)'))\n",
      "Pausing between batches...\n",
      "\n",
      "Processing batch 4/5\n",
      "Pausing between batches...\n",
      "\n",
      "Processing batch 5/5\n",
      "Error processing patent CN101070621A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN101070621A (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001FF84659D90>, 'Connection to ops.epo.org timed out. (connect timeout=15)'))\n",
      "Error processing patent JPS6023934A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JPS6023934A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84658770>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent JP2002193610A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JP2002193610A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF8465AAB0>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN104867991A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN104867991A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84655B20>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent US2005029601A1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/US2005029601A1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84654D10>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent US2005032340A1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/US2005032340A1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF8465AA80>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent NL2034508B1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/NL2034508B1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF846597C0>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN114637073A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN114637073A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF8465AC30>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN107918170A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN107918170A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84653800>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN102125582A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN102125582A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84655700>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent US5998236A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/US5998236A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84657140>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent JP2000021793A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JP2000021793A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84657230>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent US2024055256A1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/US2024055256A1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84652510>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN102877129A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN102877129A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF8465A600>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent US2011290313A1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/US2011290313A1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84658620>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN110268104A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN110268104A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF846561B0>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent CN105529266A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/CN105529266A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84656F90>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent JP3143188B2: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JP3143188B2 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84654DA0>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent WO2016021057A1: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/WO2016021057A1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84654140>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent JP2003188101A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JP2003188101A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84655700>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Error processing patent JP2009197299A: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/rest-services/family/publication/docdb/JP2009197299A (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF8465A2A0>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "Final Results:\n",
      "    first publication number              family_jurisdictions  \\\n",
      "0                CA2646325A1  [AU, CA, CN, EP, JP, TW, US, WO]   \n",
      "1               JPS58140112A                              [JP]   \n",
      "2               CN105762223A                              [CN]   \n",
      "3              JP2011111372A                              [JP]   \n",
      "4               CN100442443C                              [CN]   \n",
      "..                       ...                               ...   \n",
      "491             CN105529266A                              None   \n",
      "492              JP3143188B2                              None   \n",
      "493           WO2016021057A1                              None   \n",
      "494            JP2003188101A                              None   \n",
      "495            JP2009197299A                              None   \n",
      "\n",
      "                                        family_members  \n",
      "0    [AU2007227418A1, CA2646325A1, CN101438413A, EP...  \n",
      "1                                       [JPS58140112A]  \n",
      "2                                       [CN105762223A]  \n",
      "3                         [JP2011111372A, JP5398492B2]  \n",
      "4                           [CN100442443C, CN1737999A]  \n",
      "..                                                 ...  \n",
      "491                                               None  \n",
      "492                                               None  \n",
      "493                                               None  \n",
      "494                                               None  \n",
      "495                                               None  \n",
      "\n",
      "[496 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Global token cache\n",
    "TOKEN = None\n",
    "TOKEN_EXPIRY = 0\n",
    "\n",
    "# Constants for API endpoints\n",
    "TOKEN_URL = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "BASE_URL = \"https://ops.epo.org/3.2/rest-services\"\n",
    "\n",
    "# Load credentials from .env file\n",
    "load_dotenv()\n",
    "CONSUMER_KEY = os.getenv(\"CONSUMER_KEY\").strip()\n",
    "CONSUMER_SECRET = os.getenv(\"CONSUMER_SECRET\").strip()\n",
    "\n",
    "def get_access_token() -> str:\n",
    "    \"\"\"Get or refresh the OAuth access token.\"\"\"\n",
    "    global TOKEN, TOKEN_EXPIRY\n",
    "    if TOKEN and time.time() < TOKEN_EXPIRY:\n",
    "        return TOKEN\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CONSUMER_KEY,\n",
    "        \"client_secret\": CONSUMER_SECRET\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    response = requests.post(TOKEN_URL, data=data, headers=headers, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    TOKEN = response.json()[\"access_token\"]\n",
    "    TOKEN_EXPIRY = time.time() + 3500  # approximately 58 minutes\n",
    "    return TOKEN\n",
    "\n",
    "def validate_patent_number(patent: str) -> bool:\n",
    "    \"\"\"Perform a basic validation for the patent number format.\"\"\"\n",
    "    if not patent or len(patent.strip()) < 4:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_jurisdictions_and_members(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extract jurisdictions (as a sorted list) and family member publication numbers\n",
    "    (formatted as country+doc-number+kind) from the JSON response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        jurisdictions = set()\n",
    "        family_members = []\n",
    "        world_data = data.get('ops:world-patent-data', {})\n",
    "        patent_family = world_data.get('ops:patent-family', {})\n",
    "        members = patent_family.get('ops:family-member', [])\n",
    "        if isinstance(members, dict):\n",
    "            members = [members]\n",
    "\n",
    "        for member in members:\n",
    "            pub_ref = member.get('publication-reference', {})\n",
    "            docs = pub_ref.get('document-id', [])\n",
    "            if isinstance(docs, dict):\n",
    "                docs = [docs]\n",
    "\n",
    "            for doc in docs:\n",
    "                if doc.get('@document-id-type') == 'docdb':\n",
    "                    country = doc.get('country')\n",
    "                    if isinstance(country, dict):\n",
    "                        country = country.get('$')\n",
    "                    doc_number = doc.get('doc-number')\n",
    "                    if isinstance(doc_number, dict):\n",
    "                        doc_number = doc_number.get('$')\n",
    "                    kind = doc.get('kind')\n",
    "                    if isinstance(kind, dict):\n",
    "                        kind = kind.get('$')\n",
    "\n",
    "                    if country and doc_number and kind:\n",
    "                        jurisdictions.add(country)\n",
    "                        family_members.append(f\"{country}{doc_number}{kind}\")\n",
    "\n",
    "        return {\n",
    "            'jurisdictions': sorted(jurisdictions),\n",
    "            'family_members': sorted(set(family_members))\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return {'jurisdictions': None, 'family_members': None}\n",
    "\n",
    "def process_patent(patent: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process a single patent by sending a request to the patent family endpoint,\n",
    "    then extract family jurisdictions and family member publication numbers.\n",
    "    Returns a dict with two keys: 'jurisdictions' and 'family_members'.\n",
    "    \"\"\"\n",
    "    if not validate_patent_number(patent):\n",
    "        print(f\"Invalid patent number: {patent}\")\n",
    "        return {'jurisdictions': None, 'family_members': None}\n",
    "    try:\n",
    "        token = get_access_token()\n",
    "        url = f\"{BASE_URL}/family/publication/docdb/{quote(patent)}\" \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        if response.status_code == 403:\n",
    "            print(f\"Access forbidden for patent {patent}\")\n",
    "            return {'jurisdictions': None, 'family_members': None}\n",
    "        if response.status_code == 404:\n",
    "            print(f\"Patent {patent} not found\")\n",
    "            return {'jurisdictions': None, 'family_members': None}\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return extract_jurisdictions_and_members(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing patent {patent}: {e}\")\n",
    "        return {'jurisdictions': None, 'family_members': None}\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame, patent_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a DataFrame containing a column of patent numbers,\n",
    "    process each patent (in batches) and add two new columns:\n",
    "      - 'family_jurisdictions': sorted list of jurisdictions for the patent's family\n",
    "      - 'family_members': sorted list of publication numbers for family members\n",
    "    \"\"\"\n",
    "    if patent_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{patent_col}' not found in DataFrame\")\n",
    "    result_df = df.copy()\n",
    "    patents = result_df[patent_col].tolist()\n",
    "    total = len(patents)\n",
    "    batch_size = 100\n",
    "    request_delay = 1.2  # seconds delay between requests\n",
    "    results = {}\n",
    "\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = patents[i:i + batch_size]\n",
    "        print(f\"\\nProcessing batch {i//batch_size + 1}/{(total - 1)//batch_size + 1}\")\n",
    "        for patent in batch:\n",
    "            results[patent] = process_patent(patent)\n",
    "            time.sleep(request_delay)\n",
    "        if i + batch_size < total:\n",
    "            print(\"Pausing between batches...\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "    # Map the processed results to new DataFrame columns\n",
    "    result_df['family_jurisdictions'] = result_df[patent_col].map(\n",
    "        lambda p: results.get(p, {}).get('jurisdictions')\n",
    "    )\n",
    "    result_df['family_members'] = result_df[patent_col].map(\n",
    "        lambda p: results.get(p, {}).get('family_members')\n",
    "    )\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    try:\n",
    "        processed_df = process_dataframe(df, 'first publication number')\n",
    "        print(\"\\nFinal Results:\")\n",
    "        print(processed_df[['first publication number', 'family_jurisdictions', 'family_members']])\n",
    "        # Optionally, export the results to CSV\n",
    "        #processed_df.to_csv('patent_jurisdictions.csv', index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Processing failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57eb9c0",
   "metadata": {},
   "source": [
    "the script below looks in your /Downloads folder for any files ending in .csv , pics out the one with the newest modification timestamp , and prints its path. \n",
    "if it finds one , it then uses pandas to read that csv into a dataframe . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ed833c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Title</th>\n",
       "      <th>Inventors</th>\n",
       "      <th>Applicants</th>\n",
       "      <th>Publication number</th>\n",
       "      <th>Earliest priority</th>\n",
       "      <th>IPC</th>\n",
       "      <th>CPC</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Earliest publication</th>\n",
       "      <th>Family number</th>\n",
       "      <th>first publication date</th>\n",
       "      <th>second publication date</th>\n",
       "      <th>first publication number</th>\n",
       "      <th>second publication number</th>\n",
       "      <th>first publication country</th>\n",
       "      <th>second publication country</th>\n",
       "      <th>first filing year</th>\n",
       "      <th>earliest priority year</th>\n",
       "      <th>applicant country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DISPOSITIFS SPINTRONIQUES CONTENANT DES DOPANT...</td>\n",
       "      <td>DUKOVSKI ILIJA [US] \\r\\nMEARS ROBERT J [US] \\r...</td>\n",
       "      <td>MEARS TECHNOLOGIES INC [US]</td>\n",
       "      <td>CA2646325A1</td>\n",
       "      <td>2006-03-17</td>\n",
       "      <td>[H01L29/15, H01L29/66, H10N50/10]</td>\n",
       "      <td>[B82Y10/00 (EP), B82Y25/00 (EP), B82Y40/00 (EP...</td>\n",
       "      <td>2007-09-27</td>\n",
       "      <td>2007-09-27</td>\n",
       "      <td>38278899</td>\n",
       "      <td>2007-09-27</td>\n",
       "      <td>None</td>\n",
       "      <td>CA2646325A1</td>\n",
       "      <td>None</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SILICON SINGLE CRYSTAL</td>\n",
       "      <td>ADACHI SADAO</td>\n",
       "      <td>NIPPON TELEGRAPH &amp; TELEPHONE</td>\n",
       "      <td>JPS58140112A</td>\n",
       "      <td>1982-02-16</td>\n",
       "      <td>[H01L21/84, H01L27/12, H01L21/20, H01L21/205, ...</td>\n",
       "      <td>[H01L21/0242 (EP), H01L21/02532 (EP)]</td>\n",
       "      <td>1983-08-19</td>\n",
       "      <td>1983-08-19</td>\n",
       "      <td>12073855</td>\n",
       "      <td>1983-08-19</td>\n",
       "      <td>None</td>\n",
       "      <td>JPS58140112A</td>\n",
       "      <td>None</td>\n",
       "      <td>JP</td>\n",
       "      <td>None</td>\n",
       "      <td>1983</td>\n",
       "      <td>1982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Method for improving silicon surface lattice s...</td>\n",
       "      <td>LI XIANG</td>\n",
       "      <td>ZHEJIANG FORTUNE ENERGY CO LTD</td>\n",
       "      <td>CN105762223A</td>\n",
       "      <td>2014-12-17</td>\n",
       "      <td>[C30B33/10, H01L31/18]</td>\n",
       "      <td>[Y02P70/50 (EP)]</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>56336973</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>None</td>\n",
       "      <td>CN105762223A</td>\n",
       "      <td>None</td>\n",
       "      <td>CN</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SILICON CARBIDE SINGLE CRYSTAL, METHOD FOR PRO...</td>\n",
       "      <td>KOYANAGI NAOKI \\r\\nKOKOI HISAO</td>\n",
       "      <td>SHOWA DENKO KK</td>\n",
       "      <td>JP2011111372A \\r\\nJP5398492B2</td>\n",
       "      <td>2009-11-27</td>\n",
       "      <td>[C30B29/36]</td>\n",
       "      <td>[unkown)]</td>\n",
       "      <td>2011-06-09 \\r\\n2014-01-29</td>\n",
       "      <td>2011-06-09</td>\n",
       "      <td>44233971</td>\n",
       "      <td>2011-06-09</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>JP2011111372A</td>\n",
       "      <td>\\r\\nJP5398492B2</td>\n",
       "      <td>JP</td>\n",
       "      <td>\\r\\n</td>\n",
       "      <td>2011</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Method for preparing high electron mobility hy...</td>\n",
       "      <td>SHEN WENZHONG CHEN [CN] \\r\\nWENZHONG SHEN [CN]...</td>\n",
       "      <td>UNIV SHANGHAI JIAOTONG [CN]</td>\n",
       "      <td>CN100442443C \\r\\nCN1737999A</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>[C23C16/24, C23C16/44, H01L21/205]</td>\n",
       "      <td>[unkown)]</td>\n",
       "      <td>2006-02-22 \\r\\n2008-12-10</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>36080747</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>CN100442443C</td>\n",
       "      <td>\\r\\nCN1737999A</td>\n",
       "      <td>CN</td>\n",
       "      <td>\\r\\n</td>\n",
       "      <td>2006</td>\n",
       "      <td>2005</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                              Title  \\\n",
       "0   1  DISPOSITIFS SPINTRONIQUES CONTENANT DES DOPANT...   \n",
       "1   2                             SILICON SINGLE CRYSTAL   \n",
       "2   3  Method for improving silicon surface lattice s...   \n",
       "3   4  SILICON CARBIDE SINGLE CRYSTAL, METHOD FOR PRO...   \n",
       "4   5  Method for preparing high electron mobility hy...   \n",
       "\n",
       "                                           Inventors  \\\n",
       "0  DUKOVSKI ILIJA [US] \\r\\nMEARS ROBERT J [US] \\r...   \n",
       "1                                       ADACHI SADAO   \n",
       "2                                           LI XIANG   \n",
       "3                     KOYANAGI NAOKI \\r\\nKOKOI HISAO   \n",
       "4  SHEN WENZHONG CHEN [CN] \\r\\nWENZHONG SHEN [CN]...   \n",
       "\n",
       "                       Applicants             Publication number  \\\n",
       "0     MEARS TECHNOLOGIES INC [US]                    CA2646325A1   \n",
       "1    NIPPON TELEGRAPH & TELEPHONE                   JPS58140112A   \n",
       "2  ZHEJIANG FORTUNE ENERGY CO LTD                   CN105762223A   \n",
       "3                  SHOWA DENKO KK  JP2011111372A \\r\\nJP5398492B2   \n",
       "4     UNIV SHANGHAI JIAOTONG [CN]    CN100442443C \\r\\nCN1737999A   \n",
       "\n",
       "  Earliest priority                                                IPC  \\\n",
       "0        2006-03-17                  [H01L29/15, H01L29/66, H10N50/10]   \n",
       "1        1982-02-16  [H01L21/84, H01L27/12, H01L21/20, H01L21/205, ...   \n",
       "2        2014-12-17                             [C30B33/10, H01L31/18]   \n",
       "3        2009-11-27                                        [C30B29/36]   \n",
       "4        2005-09-08                 [C23C16/24, C23C16/44, H01L21/205]   \n",
       "\n",
       "                                                 CPC  \\\n",
       "0  [B82Y10/00 (EP), B82Y25/00 (EP), B82Y40/00 (EP...   \n",
       "1              [H01L21/0242 (EP), H01L21/02532 (EP)]   \n",
       "2                                   [Y02P70/50 (EP)]   \n",
       "3                                          [unkown)]   \n",
       "4                                          [unkown)]   \n",
       "\n",
       "            Publication date Earliest publication  Family number  \\\n",
       "0                 2007-09-27           2007-09-27       38278899   \n",
       "1                 1983-08-19           1983-08-19       12073855   \n",
       "2                 2016-07-13           2016-07-13       56336973   \n",
       "3  2011-06-09 \\r\\n2014-01-29           2011-06-09       44233971   \n",
       "4  2006-02-22 \\r\\n2008-12-10           2006-02-22       36080747   \n",
       "\n",
       "  first publication date second publication date first publication number  \\\n",
       "0             2007-09-27                    None              CA2646325A1   \n",
       "1             1983-08-19                    None             JPS58140112A   \n",
       "2             2016-07-13                    None             CN105762223A   \n",
       "3             2011-06-09              2014-01-29            JP2011111372A   \n",
       "4             2006-02-22              2008-12-10             CN100442443C   \n",
       "\n",
       "  second publication number first publication country  \\\n",
       "0                      None                        CA   \n",
       "1                      None                        JP   \n",
       "2                      None                        CN   \n",
       "3           \\r\\nJP5398492B2                        JP   \n",
       "4            \\r\\nCN1737999A                        CN   \n",
       "\n",
       "  second publication country  first filing year  earliest priority year  \\\n",
       "0                       None               2007                    2006   \n",
       "1                       None               1983                    1982   \n",
       "2                       None               2016                    2014   \n",
       "3                       \\r\\n               2011                    2009   \n",
       "4                       \\r\\n               2006                    2005   \n",
       "\n",
       "  applicant country  \n",
       "0                US  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4                CN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1553250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_df = df.head(50)\n",
    "#OR_df.to_csv('OR_df.csv' , index=False)\n",
    "result_or_df=df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77930c",
   "metadata": {},
   "source": [
    "this script uses EPO automates retrieval and processing of patent citation and classification data from Espacenet , it loads API credentials . \n",
    "first it loads the API credentials from a .env file and maintains an authentification token to authenticate requests . \n",
    "for each publication number in the dataframe , the get_patent_biblio function sends a request to EPO API endpoint to fetch the raw XML bibliographic records , then parses that XML to pull out every cited patent's publication number by grouping country code + document number + kind code . \n",
    "next , it loops over these publication number and fetches each patent's XML using the same enpoint and extract all IPC class codes  and aggregates these IPC codes back into our dataframe . \n",
    "finally it filters for any rows that yeilded at least one IPC , ensure we have at least 30 rows and display a sample of the results . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33629907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Global token cache\n",
    "TOKEN = None\n",
    "TOKEN_EXPIRY = 0\n",
    "\n",
    "# Constants for API endpoints\n",
    "TOKEN_URL = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "BASE_URL = \"https://ops.epo.org/3.2/rest-services\"\n",
    "\n",
    "# Load credentials from .env file\n",
    "load_dotenv()\n",
    "CONSUMER_KEY = os.getenv(\"CONSUMER_KEY\").strip()\n",
    "CONSUMER_SECRET = os.getenv(\"CONSUMER_SECRET\").strip()\n",
    "\n",
    "def get_access_token() -> str:\n",
    "    \"\"\"Get or refresh the OAuth access token.\"\"\"\n",
    "    global TOKEN, TOKEN_EXPIRY\n",
    "    if TOKEN and time.time() < TOKEN_EXPIRY:\n",
    "        return TOKEN\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CONSUMER_KEY,\n",
    "        \"client_secret\": CONSUMER_SECRET\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    response = requests.post(TOKEN_URL, data=data, headers=headers, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    TOKEN = response.json()[\"access_token\"]\n",
    "    # Token expires in ~58 minutes; refresh slightly before expiry.\n",
    "    TOKEN_EXPIRY = time.time() + 3500  \n",
    "    return TOKEN\n",
    "\n",
    "def get_patent_biblio(publication_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch bibliographic data for a given patent number from the EPO OPS API.\n",
    "    \n",
    "    Args:\n",
    "        publication_number (str): The publication number (e.g., \"CN112508743A\")\n",
    "        \n",
    "    Returns:\n",
    "        str: The XML response text.\n",
    "    \"\"\"\n",
    "    token = get_access_token()\n",
    "    # Construct the static endpoint URL using the provided publication number\n",
    "    url = f\"{BASE_URL}/published-data/publication/docdb/{publication_number}/biblio\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/xml\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def retrieve_citation_publication_numbers(xml_string: str) -> list:\n",
    "    \"\"\"\n",
    "    Parses an EPO patent XML string and retrieves citation publication numbers \n",
    "    from each citation's <document-id> element with document-id-type=\"docdb\".\n",
    "    The publication number is constructed as: country + doc-number + kind.\n",
    "    \n",
    "    Args:\n",
    "        xml_string (str): The XML string containing patent data.\n",
    "    \n",
    "    Returns:\n",
    "        list of str: A list of citation publication numbers.\n",
    "    \"\"\"\n",
    "    ns = {\n",
    "        'ex': \"http://www.epo.org/exchange\",\n",
    "        'ops': \"http://ops.epo.org\"\n",
    "    }\n",
    "    \n",
    "    publication_numbers = []\n",
    "    root = ET.fromstring(xml_string)\n",
    "    \n",
    "    citations = root.findall(\".//ex:bibliographic-data/ex:references-cited/ex:citation\", ns)\n",
    "    \n",
    "    for citation in citations:\n",
    "        docdb = citation.find(\".//ex:document-id[@document-id-type='docdb']\", ns)\n",
    "        if docdb is not None:\n",
    "            country = docdb.findtext(\"ex:country\", default=\"\", namespaces=ns)\n",
    "            doc_number = docdb.findtext(\"ex:doc-number\", default=\"\", namespaces=ns)\n",
    "            kind = docdb.findtext(\"ex:kind\", default=\"\", namespaces=ns)\n",
    "            pub_number = f\"{country}{doc_number}{kind}\"\n",
    "            if pub_number:\n",
    "                publication_numbers.append(pub_number)\n",
    "    \n",
    "    return publication_numbers\n",
    "\n",
    "def retrieve_ipc_classifications(xml_string: str) -> list:\n",
    "    \"\"\"\n",
    "    Parses the given patent XML string and extracts the IPC classification texts\n",
    "    from the <classifications-ipcr> element. For each classification text:\n",
    "      - Everything after (and including) the '/' character is removed.\n",
    "      - All spaces are removed from the remaining text.\n",
    "      \n",
    "    Args:\n",
    "        xml_string (str): The XML string from the OPS API.\n",
    "        \n",
    "    Returns:\n",
    "        list of str: A list of cleaned IPC classification texts.\n",
    "    \"\"\"\n",
    "    ns = {\n",
    "        'ex': \"http://www.epo.org/exchange\",\n",
    "        'ops': \"http://ops.epo.org\"\n",
    "    }\n",
    "    \n",
    "    ipcs = []\n",
    "    root = ET.fromstring(xml_string)\n",
    "    \n",
    "    for cl in root.findall(\".//ex:classifications-ipcr/ex:classification-ipcr\", ns):\n",
    "        text = cl.findtext(\"ex:text\", default=\"\", namespaces=ns)\n",
    "        if text:\n",
    "            # Remove everything after the first '/'\n",
    "            cleaned_text = text.strip().split('/')[0].strip()\n",
    "            # Remove all spaces from the cleaned text\n",
    "            cleaned_text = cleaned_text.replace(\" \", \"\")\n",
    "            ipcs.append(cleaned_text)\n",
    "    \n",
    "    return ipcs\n",
    "\n",
    "def get_citations_ipc_for_patent(publication_number: str) -> list:\n",
    "    \"\"\"\n",
    "    For a given citation publication number, fetch bibliographic data and\n",
    "    return its IPC classifications.\n",
    "    \n",
    "    Args:\n",
    "        publication_number (str): A citation publication number.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of cleaned IPC classification texts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        xml_data = get_patent_biblio(publication_number)\n",
    "        ipc_classifications = retrieve_ipc_classifications(xml_data)\n",
    "        return ipc_classifications\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching IPC for {publication_number}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_all_citations_ipc(citation_nums: list) -> list:\n",
    "    \"\"\"\n",
    "    Given a list of citation publication numbers, retrieve the IPC classifications\n",
    "    for each citation and aggregate them into one list.\n",
    "    \n",
    "    Args:\n",
    "        citation_nums (list): List of citation publication numbers.\n",
    "        \n",
    "    Returns:\n",
    "        list: Aggregated list of cleaned IPC classification texts from the citations.\n",
    "    \"\"\"\n",
    "    ipc_results = []\n",
    "    for num in citation_nums:\n",
    "        ipc = get_citations_ipc_for_patent(num)\n",
    "        ipc_results.extend(ipc)\n",
    "    return ipc_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e324e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/auth/accesstoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84653440>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:978\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    977\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    979\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:616\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    615\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001FF84653440>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/auth/accesstoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84653440>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m    \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Step 1: get citation numbers and IPC lists\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitation_numbers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m         \u001b[43mresult_or_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst publication number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m----> 7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpub\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieve_citation_publication_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_patent_biblio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpub\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitations_ipc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     10\u001b[0m         result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitation_numbers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;241m.\u001b[39mapply(get_all_citations_ipc)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Step 2: keep only rows where we actually got at least one IPC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(pub)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m    \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Step 1: get citation numbers and IPC lists\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitation_numbers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m         result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst publication number\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m pub: retrieve_citation_publication_numbers(\u001b[43mget_patent_biblio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpub\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitations_ipc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     10\u001b[0m         result_or_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitation_numbers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;241m.\u001b[39mapply(get_all_citations_ipc)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Step 2: keep only rows where we actually got at least one IPC\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 49\u001b[0m, in \u001b[0;36mget_patent_biblio\u001b[1;34m(publication_number)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_patent_biblio\u001b[39m(publication_number: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Fetch bibliographic data for a given patent number from the EPO OPS API.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m        str: The XML response text.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43mget_access_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Construct the static endpoint URL using the provided publication number\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/published-data/publication/docdb/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpublication_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/biblio\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[22], line 32\u001b[0m, in \u001b[0;36mget_access_token\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrant_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_credentials\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: CONSUMER_KEY,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m: CONSUMER_SECRET\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     31\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/x-www-form-urlencoded\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m---> 32\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTOKEN_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     34\u001b[0m TOKEN \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='ops.epo.org', port=443): Max retries exceeded with url: /3.2/auth/accesstoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FF84653440>: Failed to resolve 'ops.epo.org' ([Errno 11001] getaddrinfo failed)\"))"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "\n",
    "    # Step 1: get citation numbers and IPC lists\n",
    "    result_or_df['citation_numbers'] = (\n",
    "        result_or_df['first publication number']\n",
    "        .apply(lambda pub: retrieve_citation_publication_numbers(get_patent_biblio(pub)))\n",
    "    )\n",
    "    result_or_df['citations_ipc'] = (\n",
    "        result_or_df['citation_numbers']\n",
    "        .apply(get_all_citations_ipc)\n",
    "    )\n",
    "\n",
    "    # Step 2: keep only rows where we actually got at least one IPC\n",
    "    valid_df = result_or_df[result_or_df['citations_ipc'].apply(lambda lst: len(lst) > 0)]\n",
    "\n",
    "    # Step 3: check we have ≥ 30\n",
    "    n_valid = len(valid_df)\n",
    "    if n_valid < 30:\n",
    "        raise RuntimeError(\n",
    "            f\"Only found {n_valid} rows with citations IPC data. \"\n",
    "            \"You need at least 30 — please add more publication numbers.\"\n",
    "        )\n",
    "\n",
    "    # Step 4: pick exactly 30 of them\n",
    "    # — random sample for diversity; or use .head(30) for the first 30 in order\n",
    "    final_df = valid_df.sample(n=30, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # (Optional) inspect\n",
    "    final_df[['first publication number', 'citations_ipc']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5472b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
